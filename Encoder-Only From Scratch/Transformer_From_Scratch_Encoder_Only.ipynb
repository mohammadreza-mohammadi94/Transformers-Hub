{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd0b3c9206ac47908fe029191e2c3fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca58fe789f98430a82c1d45ca1f1dce6",
              "IPY_MODEL_9c9783d53bfe459999d55e85489a3b5d",
              "IPY_MODEL_27e06373cf6f4b6d8303b4f355ae8104"
            ],
            "layout": "IPY_MODEL_b28ce685aa1d465e80a00febb4b374e5"
          }
        },
        "ca58fe789f98430a82c1d45ca1f1dce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8cd2ba79d824821994ccbe178a6b28f",
            "placeholder": "​",
            "style": "IPY_MODEL_b512ee401d034f66beaa36f35e75aabe",
            "value": "Map: 100%"
          }
        },
        "9c9783d53bfe459999d55e85489a3b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682402784c774d7fa2d47b1b91ee473b",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_864b944d3a9d4d0e87e6a477f9080f69",
            "value": 872
          }
        },
        "27e06373cf6f4b6d8303b4f355ae8104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c763c6cc2f584e1a9bc93ff2c3d84719",
            "placeholder": "​",
            "style": "IPY_MODEL_cbd562938fc9494dba897f065d0a6c95",
            "value": " 872/872 [00:00&lt;00:00, 9174.43 examples/s]"
          }
        },
        "b28ce685aa1d465e80a00febb4b374e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cd2ba79d824821994ccbe178a6b28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b512ee401d034f66beaa36f35e75aabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "682402784c774d7fa2d47b1b91ee473b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864b944d3a9d4d0e87e6a477f9080f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c763c6cc2f584e1a9bc93ff2c3d84719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd562938fc9494dba897f065d0a6c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Transformers-Hub/blob/main/Encoder-Only%20From%20Scratch/Transformer_From_Scratch_Encoder_Only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Transformer - Encoder Only"
      ],
      "metadata": {
        "id": "NT539rZKT-GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "QHO9FyRoUDQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Aym12r9UYjh",
        "outputId": "4bcc2027-a3a4-4939-adfa-56effaa76730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLyGRS35TpzE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Attention Module"
      ],
      "metadata": {
        "id": "w2f_Sz81UEzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Multi-Head Attention mechanism as described in the Transformer architecture.\n",
        "\n",
        "    Args:\n",
        "        d_k (int): Dimension of each attention head.\n",
        "        d_model (int): Total dimension of the model (input/output embeddings).\n",
        "        n_heads (int): Number of attention heads.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_k, d_model, n_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        # Assume d_v = d_k\n",
        "        self.d_k = d_k\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.key = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.query = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.value = nn.Linear(d_model, d_k * n_heads)\n",
        "\n",
        "        # Final Linear Layer\n",
        "        self.fc = nn.Linear(d_k * n_heads, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass for Multi-Head Attention.\n",
        "\n",
        "        Args:\n",
        "            q (torch.Tensor): Query tensor of shape (batch_size, seq_len, d_model).\n",
        "            k (torch.Tensor): Key tensor of shape (batch_size, seq_len, d_model).\n",
        "            v (torch.Tensor): Value tensor of shape (batch_size, seq_len, d_model).\n",
        "            mask (torch.Tensor, optional): Mask to prevent attention to certain positions.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output of the attention mechanism.\n",
        "        \"\"\"\n",
        "        q = self.query(q) # N * T * (dh_k)\n",
        "        k = self.key(k) # N * T * (dh_k)\n",
        "        v = self.value(v) # N * T * (dh_k)\n",
        "\n",
        "        N = q.shape[0]\n",
        "        T = q.shape[1]\n",
        "\n",
        "        # Change the shape to => (N, T, h, d_k) --> (N, h, T, d_K)\n",
        "        # In order for matrix myltiply to work properly\n",
        "        q = q.view(N, T, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        k = k.view(N, T, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        v = v.view(N, T, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Compute Attention Weights\n",
        "        # (N, h, T, d_K) * (N, h, d_k, T) --> (N, h, T, T)\n",
        "        attn_scores = q @ k.transpose(-2, -1) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(\n",
        "                mask[:, None, None, :] == 0, float(\"-inf\"))\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Compute attention-weighted values\n",
        "        # (N, h, T, T) * (N, h, T, d_k) --> (N, h, T, d_k)\n",
        "        A = attn_weights @ v\n",
        "        # Reshape it back before final linear layer\n",
        "        A = A.transpose(1, 2)\n",
        "        A = A.contiguous().view(N, T, self.n_heads * self.d_k)\n",
        "\n",
        "        # Projection\n",
        "        return self.fc(A)"
      ],
      "metadata": {
        "id": "OjA_1gJhT9mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Module"
      ],
      "metadata": {
        "id": "a_oqM_dcULFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single Transformer block combining Multi-Head Attention and a Feedforward Neural Network.\n",
        "\n",
        "    Args:\n",
        "        d_k (int): Dimension of each attention head.\n",
        "        d_model (int): Total dimension of the model.\n",
        "        n_heads (int): Number of attention heads.\n",
        "        dropout_prob (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_k, d_model, n_heads, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "        self.multi_head_attn = MultiHeadAttention(d_k, d_model, n_heads)\n",
        "        self.ann = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_model * 4, d_model),\n",
        "            nn.Dropout(dropout_prob)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass for the Transformer block.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\n",
        "            mask (torch.Tensor, optional): Mask to prevent attention to certain positions.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of the same shape as input.\n",
        "        \"\"\"\n",
        "        x = self.layer_norm1(x + self.multi_head_attn(x, x, x, mask))\n",
        "        x = self.layer_norm2(x + self.ann(x))\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RrUUlK1FUMej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding"
      ],
      "metadata": {
        "id": "eYGFZE6gUPWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Adds positional encoding to input embeddings to inject order information into the model.\n",
        "\n",
        "    Args:\n",
        "        d_model (int): Total dimension of the model.\n",
        "        max_len (int): Maximum sequence length.\n",
        "        dropout_prob (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=2048, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        exp_term = torch.arange(0, d_model, 2)\n",
        "        div_term = torch.exp(exp_term * (-math.log(1000.0) / d_model))\n",
        "        # Create a positional encoding matrix\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass to add positional encoding.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Input tensor with positional encoding added.\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "Xzsr7ZJjUNAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Module"
      ],
      "metadata": {
        "id": "144KrOJBUSzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Encoder that processes input embeddings using multiple Transformer blocks.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): Size of the input vocabulary.\n",
        "        max_len (int): Maximum sequence length.\n",
        "        d_k (int): Dimension of each attention head.\n",
        "        d_model (int): Total dimension of the model.\n",
        "        n_heads (int): Number of attention heads.\n",
        "        n_layers (int): Number of Transformer blocks.\n",
        "        n_classes (int): Number of output classes.\n",
        "        dropout_prob (float): Dropout probability.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 max_len,\n",
        "                 d_k,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 n_layers,\n",
        "                 n_classes,\n",
        "                 dropout_prob):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout_prob)\n",
        "        transformer_blocks = [\n",
        "            TransformerBlock(\n",
        "                d_k,\n",
        "                d_model,\n",
        "                n_heads,\n",
        "                dropout_prob) for _ in range(n_layers)]\n",
        "        self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.fc = nn.Linear(d_model, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass for the Encoder.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len).\n",
        "            mask (torch.Tensor, optional): Mask for attention.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, n_classes).\n",
        "        \"\"\"\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoding(x)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, mask)\n",
        "\n",
        "        # Many-to-One (x has the shape of N * T * D)\n",
        "        x = x[:, 0, :]\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9BfBNhZ8URIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Dataset"
      ],
      "metadata": {
        "id": "FdBiVUOzVEtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer for a pretrained model\n",
        "checkpoint = \"distilbert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Load the SST2 dataset from GLUE benchmark\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")"
      ],
      "metadata": {
        "id": "Nk-UuufxUUM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenization function\n",
        "def tokenize_fn(batch):\n",
        "    \"\"\"\n",
        "    Tokenizes a batch of sentences using the specified tokenizer.\n",
        "\n",
        "    Args:\n",
        "        batch (dict): A batch of sentences.\n",
        "\n",
        "    Returns:\n",
        "        dict: Tokenized sentences with attention masks and input IDs.\n",
        "    \"\"\"\n",
        "    return tokenizer(batch['sentence'], truncation=True)"
      ],
      "metadata": {
        "id": "Q5BUO_CbVMeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the dataset\n",
        "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd0b3c9206ac47908fe029191e2c3fda",
            "ca58fe789f98430a82c1d45ca1f1dce6",
            "9c9783d53bfe459999d55e85489a3b5d",
            "27e06373cf6f4b6d8303b4f355ae8104",
            "b28ce685aa1d465e80a00febb4b374e5",
            "a8cd2ba79d824821994ccbe178a6b28f",
            "b512ee401d034f66beaa36f35e75aabe",
            "682402784c774d7fa2d47b1b91ee473b",
            "864b944d3a9d4d0e87e6a477f9080f69",
            "c763c6cc2f584e1a9bc93ff2c3d84719",
            "cbd562938fc9494dba897f065d0a6c95"
          ]
        },
        "id": "xD_heDjhVN2b",
        "outputId": "14ecf0e6-0d6a-4dfc-d075-b02437b55bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd0b3c9206ac47908fe029191e2c3fda"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset for training\n",
        "# Remove unnecessary columns and rename 'label' column to 'labels'\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "k0-Bt1ljVRXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and validation\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        "    collate_fn=data_collator)\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    batch_size=32,\n",
        "    collate_fn=data_collator)\n",
        "\n",
        "# Verify the DataLoader output\n",
        "for batch in train_dataloader:\n",
        "    for k, v in batch.items():\n",
        "        print(\"Key:\", k, \"Value Shape:\", v.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrznf36UVRQ2",
        "outputId": "d34868d2-3673-40fe-f84f-c0057d07a88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key: labels Value Shape: torch.Size([32])\n",
            "Key: input_ids Value Shape: torch.Size([32, 45])\n",
            "Key: attention_mask Value Shape: torch.Size([32, 45])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Model"
      ],
      "metadata": {
        "id": "ZkMdb8kxVWaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Transformer-based Encoder model (assumed already implemented as `Encoder`)\n",
        "model = Encoder(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_len=tokenizer.model_max_length,\n",
        "    d_k=16,\n",
        "    d_model=64,\n",
        "    n_heads=4,\n",
        "    n_layers=2,\n",
        "    dropout_prob=0.1,\n",
        "    n_classes=2\n",
        ")\n",
        "\n",
        "# Move the model to the available device (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "e7HP35oMVVFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(mode, criterion, optimizer, train_loader, valid_loader, epochs):\n",
        "    \"\"\"\n",
        "    Trains and evaluates the Transformer model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The Transformer model.\n",
        "        criterion: Loss function.\n",
        "        optimizer: Optimization algorithm.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        valid_loader (DataLoader): DataLoader for validation data.\n",
        "        epochs (int): Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training and validation losses for each epoch.\n",
        "    \"\"\"\n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "\n",
        "    for it in range(epochs):\n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = 0\n",
        "        n_train = 0\n",
        "        for batch in train_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "            loss = criterion(outputs, batch['labels'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * batch['input_ids'].size(0)\n",
        "            n_train += batch['input_ids'].size(0)\n",
        "\n",
        "        train_loss = train_loss / n_train\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        n_test = 0\n",
        "        for batch in valid_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "            loss = criterion(outputs, batch['labels'])\n",
        "            test_loss += loss.item() * batch['input_ids'].size(0)\n",
        "            n_test += batch['input_ids'].size(0)\n",
        "        test_loss = test_loss / n_test\n",
        "\n",
        "        # Save Losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f\"Epoch: {it+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Duration: {dt}\")\n",
        "\n",
        "    return train_losses, test_losses"
      ],
      "metadata": {
        "id": "En1mF0a3Vbal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "fsg3oTqhVj4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "train_losses, test_losses = train(model,\n",
        "                                  criterion,\n",
        "                                  optimizer,\n",
        "                                  train_dataloader,\n",
        "                                  valid_dataloader,\n",
        "                                  10)"
      ],
      "metadata": {
        "id": "knIfEr-0Vev_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a534f93-255e-4781-c868-c4b0abb3c80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10 | Train Loss: 0.5342 | Test Loss: 0.5027 | Duration: 0:00:18.005578\n",
            "Epoch: 2/10 | Train Loss: 0.3669 | Test Loss: 0.4694 | Duration: 0:00:18.918710\n",
            "Epoch: 3/10 | Train Loss: 0.2965 | Test Loss: 0.4761 | Duration: 0:00:18.407780\n",
            "Epoch: 4/10 | Train Loss: 0.2550 | Test Loss: 0.5028 | Duration: 0:00:19.309505\n",
            "Epoch: 5/10 | Train Loss: 0.2262 | Test Loss: 0.5282 | Duration: 0:00:17.934885\n",
            "Epoch: 6/10 | Train Loss: 0.2056 | Test Loss: 0.5566 | Duration: 0:00:18.220725\n",
            "Epoch: 7/10 | Train Loss: 0.1876 | Test Loss: 0.5350 | Duration: 0:00:19.045539\n",
            "Epoch: 8/10 | Train Loss: 0.1747 | Test Loss: 0.6142 | Duration: 0:00:17.878078\n",
            "Epoch: 9/10 | Train Loss: 0.1603 | Test Loss: 0.7427 | Duration: 0:00:18.985393\n",
            "Epoch: 10/10 | Train Loss: 0.1497 | Test Loss: 0.7182 | Duration: 0:00:17.998161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's accuracy\n",
        "def evaluate_accuracy(model, data_loader):\n",
        "    \"\"\"\n",
        "    Evaluates the model's accuracy on a given DataLoader.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        data_loader (DataLoader): DataLoader containing the evaluation data.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model on the dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
        "            _ , predictions = torch.max(outputs, dim=1)\n",
        "\n",
        "            n_correct += (predictions == batch['labels']).sum().item()\n",
        "            n_total += batch['labels'].size(0)\n",
        "\n",
        "    return n_correct / n_total\n",
        "\n",
        "# Calculate accuracy for train and validation sets\n",
        "train_acc = evaluate_accuracy(model, train_dataloader)\n",
        "valid_acc = evaluate_accuracy(model, valid_dataloader)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {valid_acc:.4f}\")"
      ],
      "metadata": {
        "id": "GujnJplLVirj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14215660-b1f3-4260-a0d2-ef34fcd7e3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9304\n",
            "Validation Accuracy: 0.7959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAdKhs96VipV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
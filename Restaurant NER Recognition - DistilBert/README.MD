# ğŸ” Named Entity Recognition (NER) using DistilBERT

This project fine-tunes a **DistilBERT** model for Named Entity Recognition (NER) on the **MIT Restaurant Search Dataset**. The model is trained using **Hugging Face's Transformers library** to recognize entities such as food, cuisine types, and locations in restaurant-related queries.

---

## ğŸ“Œ Features

- ğŸ“¥ **Dataset Loading**: Downloads and processes the MIT Restaurant Search dataset.
- ğŸ”¤ **Tokenization**: Uses `distilbert-base-uncased` tokenizer for processing text.
- ğŸ· **NER Tagging**: Assigns named entity labels to tokens.
- ğŸ”„ **Fine-Tuning**: Trains the model with Hugging Face's `Trainer` API.
- ğŸ“ˆ **Evaluation**: Computes precision, recall, F1-score, and accuracy using `seqeval`.
- ğŸš€ **Inference Pipeline**: Deploys a trained model for entity recognition.



## ğŸš€ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/your-username/NER-DistilBERT.git
cd NER-DistilBERT
pip install -r requirements.txt
```

### ğŸ“¦ Dependencies

- `transformers`
- `datasets`
- `torch`
- `numpy`
- `pandas`
- `evaluate`
- `seaborn`
- `matplotlib`
- `requests`

You can install them using:

```bash
pip install transformers datasets torch numpy pandas evaluate seaborn matplotlib requests
```


## ğŸ”§ Training the Model

Run the script to fine-tune DistilBERT on the dataset:

```bash
python train.py
```

This will:

1. Download and preprocess the dataset.
2. Tokenize and align entity labels.
3. Train the model using Hugging Face's Trainer.
4. Save the fine-tuned model in the `finetuned-ner/` directory.


## ğŸ“Š Model Evaluation

After training, the model is evaluated using `seqeval`, which provides precision, recall, F1-score, and accuracy metrics.


## ğŸ” Inference

To use the trained model for inference:

```python
from transformers import pipeline

ner_pipeline = pipeline('token-classification', model='finetuned-ner', aggregation_strategy='simple')

example_text = "which restaurant serves the best sushi in New York?"
print(ner_pipeline(example_text))
```

### ğŸ”¹ Sample Output

```json
[
  {"entity_group": "LOCATION", "word": "New York", "score": 0.99},
  {"entity_group": "FOOD", "word": "sushi", "score": 0.98}
]
```

## ğŸ“œ File Structure

```
NER-DistilBERT/
â”‚â”€â”€ train.py  # Main script for training and inference
â”‚â”€â”€ README.md  # Project documentation
â”‚â”€â”€ requirements.txt  # Dependencies
â”‚â”€â”€ finetuned-ner/  # Directory where the trained model is saved
```


## ğŸ¯ Future Improvements

- Fine-tune on a larger NER dataset.
- Implement hyperparameter tuning.
- Deploy as an API using FastAPI.

## ğŸ“ License

This project is open-source and available under the MIT License.

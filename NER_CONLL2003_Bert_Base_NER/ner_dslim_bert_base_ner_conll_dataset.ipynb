{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF7G68pAaWAXbFfdOwlngL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Transformers-Hub/blob/main/NER_CONLL2003_Bert_Base_NER/ner_dslim_bert_base_ner_conll_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "ZGJLKYi8ZPu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tC5XSJwtZMFb"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade huggingface_hub fsspec evaluate datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "1vQLCeXaZXrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "T2e2tbFRZXIi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model and Test NER"
      ],
      "metadata": {
        "id": "bjjHOgnCah-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline('ner', 'dslim/bert-base-NER')\n",
        "dataset = load_dataset(\"conll2003\", split='test[:5]')\n",
        "\n",
        "for item in dataset:\n",
        "    text = \" \".join(item['tokens'])\n",
        "    entities = ner(text)\n",
        "    print(f\"Text: {text[:100]}...\")\n",
        "    print(\"Entities: \", [(e[\"word\"], e[\"entity\"], e['score']) for e in entities])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou8iKMb-Ziex",
        "outputId": "a476400b-5226-4c73-a949-7f081038ddb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT ....\n",
            "Entities:  [('J', 'B-MISC', np.float32(0.48014238)), ('##AP', 'I-LOC', np.float32(0.29028258)), ('L', 'B-PER', np.float32(0.43156973)), ('##UC', 'I-LOC', np.float32(0.42212436)), ('CH', 'B-ORG', np.float32(0.64400214)), ('##IN', 'I-LOC', np.float32(0.512721)), ('##A', 'I-ORG', np.float32(0.5850009))]\n",
            "Text: Nadim Ladki...\n",
            "Entities:  [('Na', 'B-PER', np.float32(0.99730563)), ('##di', 'B-PER', np.float32(0.8018445)), ('##m', 'B-PER', np.float32(0.6068873)), ('La', 'I-PER', np.float32(0.99857855)), ('##ki', 'I-PER', np.float32(0.7398141))]\n",
            "Text: AL-AIN , United Arab Emirates 1996-12-06...\n",
            "Entities:  [('AL', 'B-LOC', np.float32(0.9976654)), ('-', 'I-LOC', np.float32(0.9957873)), ('AI', 'I-LOC', np.float32(0.9619766)), ('##N', 'I-LOC', np.float32(0.9851366)), ('United', 'B-LOC', np.float32(0.9994467)), ('Arab', 'I-LOC', np.float32(0.9993622)), ('Emirates', 'I-LOC', np.float32(0.99942786))]\n",
            "Text: Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C cha...\n",
            "Entities:  [('Japan', 'B-LOC', np.float32(0.9998572)), ('Asian', 'B-MISC', np.float32(0.99837995)), ('Cup', 'I-MISC', np.float32(0.9979042)), ('Syria', 'B-LOC', np.float32(0.9997607)), ('Group', 'B-MISC', np.float32(0.70048565)), ('C', 'I-MISC', np.float32(0.8535792))]\n",
            "Text: But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 d...\n",
            "Entities:  [('China', 'B-LOC', np.float32(0.9998673)), ('Uzbekistan', 'B-LOC', np.float32(0.9997266))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Develop NER Model"
      ],
      "metadata": {
        "id": "zSX6fGSxcCPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------#\n",
        "# Libraries       #\n",
        "#-----------------#\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import logging\n",
        "\n",
        "#-----------------#\n",
        "# Logging         #\n",
        "#-----------------#\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "#-----------------#\n",
        "# Configuration   #\n",
        "#-----------------#\n",
        "MODEL_NAME = \"dslim/bert-base-NER\"\n",
        "DATASET_NAME = \"conll2003\"\n",
        "DATASET_SPLIT = \"test[:5]\""
      ],
      "metadata": {
        "id": "yY_DN4IZbJar"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "lBVEmSvNc6XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_entities(entities):\n",
        "    \"\"\"\n",
        "    Formats the raw entity output from the pipeline for better readability.\n",
        "\n",
        "    Args:\n",
        "        entities (list): A list of dictionaries, where each dictionary\n",
        "                         represents an entity found by the NER model.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples, each containing (word, entity_label, score).\n",
        "    \"\"\"\n",
        "    formatted = []\n",
        "    for entity in entities:\n",
        "        # Standardize access to entity details\n",
        "        word = entity.get(\"word\", \"N/A\")\n",
        "        # THIS IS THE KEY CHANGE: \"entity\" -> \"entity_group\"\n",
        "        entity_label = entity.get(\"entity_group\", \"N/A\") # Use \"entity_group\" with aggregation\n",
        "        score = entity.get(\"score\", 0.0)\n",
        "        formatted.append((word, entity_label, f\"{score:.4f}\")) # Format score for readability\n",
        "    return formatted"
      ],
      "metadata": {
        "id": "mFQNtbPkc5yQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_for_ner(text, ner_pipeline):\n",
        "    \"\"\"\n",
        "    Processes a single text string using the NER pipeline.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to analyze.\n",
        "        ner_pipeline (transformers.Pipeline): The initialized NER pipeline.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of formatted entities found in the text.\n",
        "    \"\"\"\n",
        "    if not text.strip(): # Handle empty strings\n",
        "        logging.warning(\"Received empty text for NER processing.\")\n",
        "        return []\n",
        "    try:\n",
        "        raw_entities = ner_pipeline(text)\n",
        "        return format_entities(raw_entities)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during NER processing for text: '{text[:50]}...': {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "5ZAa2bs6c5vT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to load the NER model, dataset, and perform entity recognition.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Loading NER model: {MODEL_NAME}\")\n",
        "    try:\n",
        "        ner_pipeline = pipeline(\"ner\", model=MODEL_NAME, aggregation_strategy=\"simple\")\n",
        "        # Using aggregation_strategy=\"simple\" groups sub-word tokens (like ##ing for 'running')\n",
        "        # into single entities. Other options: \"first\", \"average\", \"max\".\n",
        "        # \"none\" would return entities for each token.\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to load NER model: {e}\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Loading dataset: {DATASET_NAME}, split: {DATASET_SPLIT}\")\n",
        "    try:\n",
        "        dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to load dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    logging.info(\"Starting NER processing on the dataset...\")\n",
        "    for i, item in enumerate(dataset):\n",
        "        # The CoNLL2003 dataset items have 'tokens' and 'ner_tags'\n",
        "        # 'tokens' is a list of words.\n",
        "        text = \" \".join(item[\"tokens\"])\n",
        "\n",
        "        # It's also insightful to see the *ground truth* labels if available\n",
        "        ground_truth_tags = item.get(\"ner_tags\", []) # ner_tags are numerical in conll2003\n",
        "        # To make ground truth human-readable, you'd need the dataset's feature info:\n",
        "        # feature_info = dataset.features[\"ner_tags\"].feature\n",
        "        # ground_truth_labels = [feature_info.int2str(tag) for tag in ground_truth_tags]\n",
        "\n",
        "        print(f\"\\n--- Sample {i+1} ---\")\n",
        "        print(f\"Original Text (first 100 chars): {text[:100]}...\")\n",
        "        # print(f\"Ground Truth NER Tags (numerical): {ground_truth_tags}\")\n",
        "        # print(f\"Ground Truth NER Labels: {ground_truth_labels}\") # If you convert them\n",
        "\n",
        "        predicted_entities = process_text_for_ner(text, ner_pipeline)\n",
        "\n",
        "        if predicted_entities:\n",
        "            print(\"Predicted Entities:\")\n",
        "            for word, entity_label, score in predicted_entities:\n",
        "                print(f\"  - Word: \\\"{word}\\\", Type: {entity_label}, Confidence: {score}\")\n",
        "        else:\n",
        "            print(\"  No entities predicted or an error occurred.\")\n",
        "\n",
        "    logging.info(\"NER processing finished.\")"
      ],
      "metadata": {
        "id": "VGSr0qb1c5si"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVQSI3F2c5pu",
        "outputId": "b65634fa-f105-4eeb-ea65-827813764a7e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 1 ---\n",
            "Original Text (first 100 chars): SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT ....\n",
            "Predicted Entities:\n",
            "  - Word: \"J\", Type: MISC, Confidence: 0.4801\n",
            "  - Word: \"##AP\", Type: LOC, Confidence: 0.2903\n",
            "  - Word: \"L\", Type: PER, Confidence: 0.4316\n",
            "  - Word: \"##UC\", Type: LOC, Confidence: 0.4221\n",
            "  - Word: \"CH\", Type: ORG, Confidence: 0.6440\n",
            "  - Word: \"##IN\", Type: LOC, Confidence: 0.5127\n",
            "  - Word: \"##A\", Type: ORG, Confidence: 0.5850\n",
            "\n",
            "--- Sample 2 ---\n",
            "Original Text (first 100 chars): Nadim Ladki...\n",
            "Predicted Entities:\n",
            "  - Word: \"Na\", Type: PER, Confidence: 0.9973\n",
            "  - Word: \"##di\", Type: PER, Confidence: 0.8018\n",
            "  - Word: \"##m La\", Type: PER, Confidence: 0.8027\n",
            "  - Word: \"##ki\", Type: PER, Confidence: 0.7398\n",
            "\n",
            "--- Sample 3 ---\n",
            "Original Text (first 100 chars): AL-AIN , United Arab Emirates 1996-12-06...\n",
            "Predicted Entities:\n",
            "  - Word: \"AL - AIN\", Type: LOC, Confidence: 0.9851\n",
            "  - Word: \"United Arab Emirates\", Type: LOC, Confidence: 0.9994\n",
            "\n",
            "--- Sample 4 ---\n",
            "Original Text (first 100 chars): Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C cha...\n",
            "Predicted Entities:\n",
            "  - Word: \"Japan\", Type: LOC, Confidence: 0.9999\n",
            "  - Word: \"Asian Cup\", Type: MISC, Confidence: 0.9981\n",
            "  - Word: \"Syria\", Type: LOC, Confidence: 0.9998\n",
            "  - Word: \"Group C\", Type: MISC, Confidence: 0.7770\n",
            "\n",
            "--- Sample 5 ---\n",
            "Original Text (first 100 chars): But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 d...\n",
            "Predicted Entities:\n",
            "  - Word: \"China\", Type: LOC, Confidence: 0.9999\n",
            "  - Word: \"Uzbekistan\", Type: LOC, Confidence: 0.9997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B09bGFamc5kq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
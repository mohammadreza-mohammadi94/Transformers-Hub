{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "T2Kpgjav_rDo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBhuxlEg_kmy"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade datasets huggingface_hub fsspec rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model From HF"
      ],
      "metadata": {
        "id": "96YfluIv_u7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "kvE8cyvUAppt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define summarizer\n",
        "summarizer = pipeline('summarization',\n",
        "                     model='facebook/bart-large-cnn')\n",
        "dataset = load_dataset('cnn_dailymail', '3.0.0', split='test[:3]')\n",
        "\n",
        "\n",
        "print(\"_\" * 50)\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "FNjQkjeh_suB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization\n",
        "#--------------\n",
        "\n",
        "# Defien score metric\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "\n",
        "# Summarization\n",
        "for i, article in enumerate(dataset):\n",
        "    text = article['article'][:1000]\n",
        "    reference = article['highlights']\n",
        "    summary = summarizer(text, max_length=100, min_length=30, do_sample=False)[0][\"summary_text\"]\n",
        "    # Check score\n",
        "    scores = scorer.score(text, summary)\n",
        "\n",
        "    print(f\"\\n--- Sample {i+1} ---\")\n",
        "    pprint(f\"Original Text: {text[:100]}...\")\n",
        "    pprint(f\"Reference Summary: {reference}\")\n",
        "    pprint(f\"Summary: {summary}\")\n",
        "    print(\"ROUGE Scores:\")\n",
        "    for metric, score in scores.items():\n",
        "        print(f\"{metric}: P={score.precision:.2f}, R={score.recall:.2f}, F1={score.fmeasure:.2f}\")"
      ],
      "metadata": {
        "id": "ruGO2reZAFzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbbMWGm5BJ_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrtZ_Qi_BJ6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NXmcW_tBJ4L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}